# @package _global_
defaults:
  - override /model: hstu
  - override /data: large

# ============================================================================
# Experiment 6: Sampled Softmax Baseline (No Annealing)
# ============================================================================
#
# Purpose: Baseline comparison using fixed temperature.
# Compare with InfoNCE+Annealing to measure improvement from annealing.
#
# This uses the original SampledSoftmaxLoss with fixed temperature.
# ============================================================================

tags: ["sampled-softmax", "fixed-temp", "baseline"]

model:
  optimizer:
    lr: 0.0005
    weight_decay: 0.1

  configure_optimizer_params:
    monitor: val/mrr
    mode: max

  item_embedding_dim: 128

  preprocessor:
    dropout_rate: 0.2
    content_emb_mlp: true
    content_emb_hidden_dim: 512

  sequence_encoder:
    embedding_dim: ${model.item_embedding_dim}
    item_embedding_dim: ${model.item_embedding_dim}
    attention_dim: ${model.item_embedding_dim}
    linear_dim: ${model.item_embedding_dim}
    num_blocks: 4
    num_heads: 2
    linear_dropout_rate: 0.2
    attn_dropout_rate: 0.1

  negative_sampler:
    _target_: tc_news_rec.models.negative_samplers.negative_samplers.GlobalNegativeSampler
    l2_normalize: true

  # Fixed temperature SampledSoftmax (original loss)
  loss:
    _target_: tc_news_rec.models.losses.losses.SampledSoftmaxLoss
    num_to_sample: 1024
    softmax_temperature: 0.1    # Fixed temperature
    use_hard_negatives: false

data:
  sliding_window_augment: true
  sliding_window_step: 2
  sliding_window_min_len: 3
  batch_size: 256

trainer:
  gradient_clip_val: 1.0
  val_check_interval: 500
  log_every_n_steps: 50
  max_epochs: 15
